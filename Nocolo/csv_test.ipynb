{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZRUmsp8yBU-",
    "outputId": "31dce23f-a801-4781-bb31-6b012576e821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: DotMap in c:\\users\\avitr\\anaconda3\\lib\\site-packages (1.3.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for pyyaml: [Errno 2] No such file or directory: 'c:\\\\users\\\\avitr\\\\anaconda3\\\\lib\\\\site-packages\\\\PyYAML-5.4.1.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install DotMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lt83zAIiyIDC"
   },
   "outputs": [],
   "source": [
    "from dotmap import DotMap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re, string\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "S77xkHWyyIrn"
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 6375: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m [DotMap(json\u001b[38;5;241m.\u001b[39mloads(x)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_all_ann (2).json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      2\u001b[0m js \u001b[38;5;241m=\u001b[39m [json\u001b[38;5;241m.\u001b[39mloads(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mopen\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_all_ann (2).json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      3\u001b[0m js[\u001b[38;5;241m3\u001b[39m]\n",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m [DotMap(json\u001b[38;5;241m.\u001b[39mloads(x)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_all_ann (2).json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      2\u001b[0m js \u001b[38;5;241m=\u001b[39m [json\u001b[38;5;241m.\u001b[39mloads(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mopen\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_all_ann (2).json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      3\u001b[0m js[\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x81 in position 6375: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "data = [DotMap(json.loads(x)) for x in open('new_all_ann (2).json', 'r')]\n",
    "js = [json.loads(x) for x in open ('new_all_ann (2).json', 'r')]\n",
    "js[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2HMWGlayQq6"
   },
   "outputs": [],
   "source": [
    "lis = [[\"text\", \"intent\", \"arg\", \"enType\", \"value\"]]\n",
    "\n",
    "for j in data:\n",
    "    for a in j.intents[0].arguments:\n",
    "        element = [j.text, j.intents[0].intent, a.arg, a.enType, a.value]\n",
    "        lis.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tneiuJRIyRIS"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lis[1:], columns=lis[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkZQmE7gyS5X"
   },
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmM_2tKcyVTl"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMa3sgwyyZJS"
   },
   "outputs": [],
   "source": [
    "df['Embeddings'] = df['text'].progress_apply(lambda x: model.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jZnLuB7yZSD"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4eaMQMWjyccy"
   },
   "outputs": [],
   "source": [
    "def get_top5_embedding_rows(user_input):\n",
    "\n",
    "    # convert user_input to embeddings\n",
    "\n",
    "    vect2 = model.encode(user_input).reshape(1,-1)\n",
    "\n",
    "    # make a copy of original dataframe\n",
    "    #df_temp = df.copy()\n",
    "    df_temp = df.apply(eval)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_temp['similarity'] = df_temp['Embeddings'].progress_apply(lambda vect1:cosine_similarity(vect1.reshape(1,-1), vect2)[0][0])\n",
    "\n",
    "\n",
    "    top_5 = df_temp.sort_values('similarity',ascending=False).head(10)\n",
    "\n",
    "\n",
    "\n",
    "    return top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsiYZD4SyjH1"
   },
   "outputs": [],
   "source": [
    "get_top5_embedding_rows('')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
