{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0cf087",
   "metadata": {
    "id": "8b0cf087",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-1\">Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Data-Preprocessing\" data-toc-modified-id=\"1.-Data-Preprocessing-1.1\">1. Data Preprocessing</a></span></li><li><span><a href=\"#2.-Machine-Learning-Models\" data-toc-modified-id=\"2.-Machine-Learning-Models-1.2\">2. Machine Learning Models</a></span></li><li><span><a href=\"#3.-Deep-Learning-Models\" data-toc-modified-id=\"3.-Deep-Learning-Models-1.3\">3. Deep Learning Models</a></span></li><li><span><a href=\"#4.-Hugging-Face-Models\" data-toc-modified-id=\"4.-Hugging-Face-Models-1.4\">4. Hugging Face Models</a></span></li><li><span><a href=\"#5.-Model-Comparison-and-Selection\" data-toc-modified-id=\"5.-Model-Comparison-and-Selection-1.5\">5. Model Comparison and Selection</a></span></li><li><span><a href=\"#6.-Interface\" data-toc-modified-id=\"6.-Interface-1.6\">6. Interface</a></span></li><li><span><a href=\"#7.-Conclusion\" data-toc-modified-id=\"7.-Conclusion-1.7\">7. Conclusion</a></span></li></ul></li><li><span><a href=\"#Pre-Processing\" data-toc-modified-id=\"Pre-Processing-2\">Pre-Processing</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a73b03",
   "metadata": {
    "id": "a4a73b03"
   },
   "source": [
    "* Student name: Natalia Edelson\n",
    "* Student pace: Flex\n",
    "* Scheduled project review date/time: April 6, 2023\n",
    "* Instructor name: Morgan Jones\n",
    "* Blog:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479955cd",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e9544ba",
   "metadata": {
    "id": "5e9544ba"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import fasttext\n",
    "import bz2\n",
    "import csv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ddc6a05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ddc6a05",
    "outputId": "aa635a37-f4b8-41e3-9c59-5eed93e40983"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -mpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: fasttext in /Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages (0.9.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in /Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages (from fasttext) (2.10.4)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages (from fasttext) (52.0.0.post20210125)\n",
      "Requirement already satisfied: numpy in /Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages (from fasttext) (1.24.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -mpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mpy (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution - (/Users/nataliaedelson/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "OK3UqnipJNkj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OK3UqnipJNkj",
    "outputId": "fe6bb99c-be66-4aef-b88c-6ce241a281bb"
   },
   "outputs": [],
   "source": [
    "# Open the file named \"test.ft.txt\" in read mode\n",
    "# file = open('/content/test.ft.txt', 'r')\n",
    "\n",
    "# Read the contents of the file\n",
    "# contents = file.read()\n",
    "\n",
    "# Print the contents of the file\n",
    "# print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dWWCpwk-JjiX",
   "metadata": {
    "id": "dWWCpwk-JjiX"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.ft.txt.bz2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2324bc458a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Obtain the files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.ft.txt.bz2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.ft.txt.bz2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/bz2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, buffering, compresslevel)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closefp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.ft.txt.bz2'"
     ]
    }
   ],
   "source": [
    "# Obtain the files. \n",
    "train_file = bz2.BZ2File('train.ft.txt.bz2')\n",
    "test_file = bz2.BZ2File('test.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0QbbD-NJ6Sq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "a0QbbD-NJ6Sq",
    "outputId": "06fa2c09-29a7-4e87-a0c6-611fff72c38b"
   },
   "outputs": [],
   "source": [
    "# Read the contents of the files into variables\n",
    "train_file_lines = train_file.readlines()\n",
    "test_file_lines = test_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_file, test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e97f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_lines = [x.decode('utf-8') for x in train_file_lines]\n",
    "test_file_lines = [x.decode('utf-8') for x in test_file_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa1780",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_file_lines), type(test_file_lines), \"\\n\")\n",
    "\n",
    "print(\"Train Data Volume:\", len(train_file_lines), \"\\n\")\n",
    "print(\"Test Data Volume:\", len(test_file_lines), \"\\n\\n\")\n",
    "\n",
    "print(\"Demo: \", \"\\n\")\n",
    "for x in train_file_lines[:2]:\n",
    "    print(x, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c6fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Labels from the data\n",
    "\n",
    "train_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_file_lines]\n",
    "test_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_file_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a81d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4mxY4w-rLKtr",
   "metadata": {
    "id": "4mxY4w-rLKtr"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "def plot(data_split):\n",
    "# Create a Pandas DataFrame from the train_labels array\n",
    "    df = pd.DataFrame({'label': data_split})\n",
    "\n",
    "# Calculate the frequency of each label\n",
    "    label_counts = df['label'].value_counts().reset_index()\n",
    "    label_counts.columns = ['label', 'count']\n",
    "\n",
    "# Define a custom color palette\n",
    "    #colors = ['rgb(166,206,227))', \n",
    "          #'rgbrgb(31,120,180)', \n",
    "          #'rgb(178,223,138)', \n",
    "          #'rgb(51,160,44)',\n",
    "         # 'rgb(251,154,153)', \"rgb(227,26,28)\"]\n",
    "    colors =  [[0, \"rgb(166,206,227)\"],\n",
    "                [0.25, \"rgb(31,120,180)\"],\n",
    "                [0.45, \"rgb(178,223,138)\"],\n",
    "                [0.65, \"rgb(51,160,44)\"],\n",
    "                [0.85, \"rgb(251,154,153)\"],\n",
    "                [1, \"rgb(227,26,28)\"]]        \n",
    "            \n",
    "  \n",
    "    \n",
    "# Create the bar chart using Plotly Express\n",
    "    fig = px.bar(label_counts, x='label', y='count', \n",
    "             color='label', \n",
    "             color_discrete_sequence=colors, \n",
    "             labels={'label': 'Labels', \n",
    "                     'count': 'Counts'})\n",
    "\n",
    "#Set the plot title\n",
    "    fig.update_layout(title={'text': ' Labels Distribution',\n",
    "                        'x': 0.5})\n",
    "\n",
    "# Show the plot\n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ac5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6cd1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Reviews from the data\n",
    "\n",
    "train_sentences = [x.split(' ', 1)[1][:-1] for x in train_file_lines]\n",
    "test_sentences = [x.split(' ', 1)[1][:-1] for x in test_file_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe7bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine your train_sentences and train_labels into a single dataframe\n",
    "train_data = pd.DataFrame({'sentence': train_sentences, 'label': train_labels})\n",
    "\n",
    "# Print the resulting dataframe\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771cb29",
   "metadata": {},
   "source": [
    "#### 1. Data Preprocessing\n",
    "\n",
    "Text cleaning and normalization (e.g., removing stopwords, stemming, lemmatization).\n",
    "Text vectorization (e.g., using CountVectorizer or TF-IDF).\n",
    "Splitting the dataset into training and testing sets.\n",
    "\n",
    "#### 2. Machine Learning Models\n",
    "\n",
    "Training and evaluating two machine learning models using the preprocessed data.\n",
    "Using TF-IDF and Word2Vec for text vectorization.\n",
    "\n",
    "#### 3. Deep Learning Models\n",
    "\n",
    "Training and evaluating two deep learning models using the preprocessed data.\n",
    "Using TF-IDF and Word2Vec for text vectorization.\n",
    "\n",
    "#### 4. Hugging Face Models\n",
    "\n",
    "Training and evaluating two Hugging Face models using the preprocessed data.\n",
    "Using pre-trained models from the Hugging Face model hub.\n",
    "\n",
    "#### 5. Model Comparison and Selection\n",
    "\n",
    "Comparing the performance of all the models and selecting the best one based on metrics such as accuracy, precision, recall, and F1-score.\n",
    "Showing the confusion matrix and classification report for the selected model.\n",
    "Visualizing the accuracy and loss over epochs using graphs.\n",
    "\n",
    "#### 6. Interface\n",
    "\n",
    "Using the best model to create an interactive interface for users to input text and get predictions.\n",
    "\n",
    "#### 7. Conclusion\n",
    "\n",
    "Summarizing the main findings and limitations of the notebook.\n",
    "Suggestions for future work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d1e606",
   "metadata": {},
   "source": [
    "### Pre-Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c55208b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "tqdm.pandas() # Monitor completion \n",
    "ps = PorterStemmer() # defining and applying stemming to words in the text.\n",
    "\n",
    "# text patterns that we want to remove from the text \n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "# Replace 3 or more consecutive letters by 2 letter.\n",
    "sequencePattern   = r\"(.)\\1\\1+\" \n",
    "seqReplacePattern = r\"\\1\\1\"\n",
    "nltk.download('stopwords')\n",
    "# Listst of common words we will removed from text.\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\")) \n",
    "\n",
    "# The preprocess() function takes in the tweet and\n",
    "# applies various text cleaning techniques to it.\n",
    "\n",
    "def preprocess(text,apply_stem=True):\n",
    "    \n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    text = re.sub(sequencePattern, seqReplacePattern, text)\n",
    "    \n",
    "    tokens = [] # Initializing an empty list to store tokenized words.\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:  # Checking if the word is not a stopword\n",
    "            \n",
    "            if apply_stem:\n",
    "               # Stemming to the word using the PorterStemmer if True\n",
    "                tokens.append(ps.stem(token))  \n",
    "            else:\n",
    "                # Adding the original word if stemming is not applied.\n",
    "                tokens.append(token) \n",
    "    # Joining and retuning the list of tokenized words into a single string\n",
    "    return \" \".join(tokens)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
