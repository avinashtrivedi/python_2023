{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a48848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np \n",
    "\n",
    "from dmba import regressionSummary, classificationSummary, liftChart, gainsChart\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4979a565",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2622aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "df_q1 = pd.read_excel(r\"D:\\OneDrive - NITT\\Custom_Download\\regression_metric_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0906a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 0.3077\n",
      "       Root Mean Squared Error (RMSE) : 2.0096\n",
      "            Mean Absolute Error (MAE) : 1.6538\n",
      "          Mean Percentage Error (MPE) : -17.3397\n",
      "Mean Absolute Percentage Error (MAPE) : 61.8269\n"
     ]
    }
   ],
   "source": [
    "# get true and predicted value\n",
    "y_true = df_q1['Y_actual']\n",
    "y_pred = df_q1['Y_predicted']\n",
    "\n",
    "# call regressionSummary() function to print Regression statistics\n",
    "regressionSummary(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed829ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y_actual       1\n",
       "Y_predicted    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_q1.min() # check for Minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2ed099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y_actual       5\n",
       "Y_predicted    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_q1.max() # check for Maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87e559",
   "metadata": {},
   "source": [
    "- Though \"Mean Error\",RMSE,MAE is small because values are in the range of 1 to 5, but overall the model is giving poor performance, that can be concluded from huge MAPE and negative Mean Percentage Error (MPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de1d30",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "155068cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "df_q2 = pd.read_csv(r\"D:\\OneDrive - NITT\\Custom_Download\\Assignment_2_Q2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdf8538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.5167)\n",
      "\n",
      "       Prediction\n",
      "Actual  0  1\n",
      "     0 27 24\n",
      "     1  5  4\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# get true and predicted value\n",
    "y_true = df_q2['Actual']\n",
    "y_pred = df_q2['Predicted']\n",
    "\n",
    "# print Confusion Matrix using classificationSummary\n",
    "print(classificationSummary(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "932e24b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get true negative ,true positive ,false negative and false positive\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97fbc09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp #  true positive, the model correctly predicts the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5afe7e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn # true negative, the model correctly predicts the negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4251d449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false positive, It should be predicted as Negative but \n",
    "# the model incorrectly predicts the positive class\n",
    "fp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dddf083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false negative, It should be predicted as positive but \n",
    "# the model incorrectly predicts the negative class\n",
    "\n",
    "fn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2185fca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.529\n",
      "Sensitivity: 0.444\n",
      "accuracy: 0.517\n",
      "F1_Score: 0.216\n"
     ]
    }
   ],
   "source": [
    "# Specificity or true negative rate\n",
    "TNR = tn/(tn+fp) \n",
    "\n",
    "# Sensitivity, recall, or true positive rate\n",
    "TPR = tp/(tp+fn)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (tp+tn)/(tp+fp+fn+tn)\n",
    "\n",
    "# Precision \n",
    "PPV = tp/(tp+fp)\n",
    "\n",
    "# F1 Score\n",
    "F1_Score = 2*(PPV*TPR)/(PPV+TPR)\n",
    "\n",
    "# print the result\n",
    "print(\"Specificity:\",round(TNR,3))\n",
    "print(\"Sensitivity:\",round(TPR,3))\n",
    "print(\"accuracy:\",round(ACC,3))\n",
    "print(\"F1_Score:\",round(F1_Score,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e10c38",
   "metadata": {},
   "source": [
    "- Based on Confusion Matrix, i can say that out of 51 time (27+24) class-0, only 27 times its getting correctly predicted. Similarly out of 9 time class-1 (5+4), only 4 times its getting correctly predicted.\n",
    "\n",
    "- Based on the accuracy score of mere 0.517, it is safe to conclude that the model was not performing well i.e its probability of correctness is just half i.e 51.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7941eaae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
