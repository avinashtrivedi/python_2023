{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c3ed4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_feature\u001b[39m(file_path):\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;66;03m# Extracting MFCC feature\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def get_feature(file_path):\n",
    "  # Extracting MFCC feature\n",
    "  mfcc = get_mfcc(file_path)\n",
    "  mfcc_mean = mfcc.mean(axis=1)\n",
    "  mfcc_min = mfcc.min(axis=1)\n",
    "  mfcc_max = mfcc.max(axis=1)\n",
    "  mfcc_feature = np.concatenate( (mfcc_mean, mfcc_min, mfcc_max) )\n",
    "\n",
    "  # Extracting Mel Spectrogram feature\n",
    "  melspectrogram = get_melspectrogram(file_path)\n",
    "  melspectrogram_mean = melspectrogram.mean(axis=1)\n",
    "  melspectrogram_min = melspectrogram.min(axis=1)\n",
    "  melspectrogram_max = melspectrogram.max(axis=1)\n",
    "  melspectrogram_feature = np.concatenate( (melspectrogram_mean, melspectrogram_min, melspectrogram_max) )\n",
    "\n",
    "  # Extracting chroma vector feature\n",
    "  chroma = get_chroma_vector(file_path)\n",
    "  chroma_mean = chroma.mean(axis=1)\n",
    "  chroma_min = chroma.min(axis=1)\n",
    "  chroma_max = chroma.max(axis=1)\n",
    "  chroma_feature = np.concatenate( (chroma_mean, chroma_min, chroma_max) )\n",
    "\n",
    "  # Extracting tonnetz feature\n",
    "  tntz = get_tonnetz(file_path)\n",
    "  tntz_mean = tntz.mean(axis=1)\n",
    "  tntz_min = tntz.min(axis=1)\n",
    "  tntz_max = tntz.max(axis=1)\n",
    "  tntz_feature = np.concatenate( (tntz_mean, tntz_min, tntz_max) )\n",
    "\n",
    "  feature = np.concatenate( (chroma_feature, melspectrogram_feature, mfcc_feature, tntz_feature) )\n",
    "  return feature\n",
    "\n",
    "X = np.load(r'D:\\OneDrive - NITT\\Custom_Download\\X_1218.npy')\n",
    "y = np.load(r'D:\\OneDrive - NITT\\Custom_Download\\y_1218.npy')\n",
    "\n",
    "y_unique = np.unique(y)\n",
    "print(y_unique) # [0 1 2 3 4 5 6 7 8 9]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "(5803, 498)\n",
    "(5803,)\n",
    "\n",
    "y = to_categorical(y, num_classes=10)\n",
    "\n",
    "test_size = 0.25\n",
    "validation_size = 0.2\n",
    "\n",
    "\n",
    "# create train, validation and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=1, shuffle=True, stratify=y)\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size, random_state=1, shuffle=True, stratify=y_train)\n",
    "\n",
    "\n",
    "# Training set shape: (3481, 498)\n",
    "# Validation set shape: (871, 498)\n",
    "# Test set shape: (1451, 498)\n",
    "# Training set Y shape: (3481, 10)\n",
    "\n",
    "def get_train_test(split_num, X, y):\n",
    "    kf = KFold(n_splits=split_num)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    train_test_indices = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        train_test_indices.append((train_index, test_index))\n",
    "    return train_test_indices\n",
    "\n",
    "split_num = 10  # number of splits for cross-validation\n",
    "train_test_indices = get_train_test(split_num, X_train, y_train)\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "def test_model(input_shape):\n",
    "    inputs = keras.Input(shape=(input_shape), name=\"features\")\n",
    "    x = keras.layers.Dense(300, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = keras.layers.Dense(200, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    x = keras.layers.Dense(100, activation=\"relu\", name=\"dense_3\")(x)\n",
    "    outputs = keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "    # Optimizer\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    # Loss function to minimize\n",
    "    #loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    loss='categorical_crossentropy',\n",
    "    # List of metrics to monitor,\n",
    "    metrics=['accuracy', Precision(), Recall()])\n",
    "    return model\n",
    "\n",
    "input_shape = (498)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "fold_count = 0\n",
    "\n",
    "for train_index, test_index in train_test_indices:\n",
    "    fold_count += 1\n",
    "    print(f\"Fold #{fold_count}\")\n",
    "\n",
    "    X_train_kf, X_test_kf = X_train[train_index], X_train[test_index]\n",
    "    y_train_kf, y_test_kf = y_train[train_index], y_train[test_index]\n",
    "\n",
    "    model = test_model(input_shape)\n",
    "    history = model.fit(X_train_kf, y_train_kf, epochs=100, batch_size=32, validation_data=(X_test_kf, y_test_kf))\n",
    "    test_loss, test_acc, test_precision, test_recall = model.evaluate(X_test_kf, y_test_kf, verbose=1)\n",
    "    print('Accuracy: %.2f' % (test_acc*100))\n",
    "    if test_acc > best_accuracy:\n",
    "        best_accuracy = test_acc\n",
    "        best_model = model\n",
    "        print(\"Best accuracy so far: %.2f\" % best_accuracy)\n",
    "\n",
    "print(\"Training complete!\")\n",
    "print(\"Best accuracy overall: %.2f\" % best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524a095",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_model_1(model, short_segments, labels):\n",
    "    input_details = model.get_input_details()\n",
    "    output_details = model.get_output_details()\n",
    "    print(\"Expected Input Shape:\", input_details[0]['shape'])  # Expected Input Shape: [1 498]\n",
    "\n",
    "    # Initialize an empty array to store individual predictions\n",
    "    segment_predictions = []\n",
    "\n",
    "    for mfcc in short_segments:\n",
    "        print(\"Input Shape:\", mfcc.shape)  # Input Shape: (498,)\n",
    "\n",
    "        # Ensure the batch dimension is added\n",
    "        input_data = np.expand_dims(mfcc, axis=-1)\n",
    "        #input_data = mfcc.astype(np.float32)\n",
    "        input_data = input_data.astype(np.float32)\n",
    "\n",
    "        print(\"Input Shape after expansion:\", input_data.shape)  # Input Shape after expansion: (1, 498)\n",
    "\n",
    "        # Check and adjust the shape if necessary\n",
    "        # if input_data.shape[1] != 498:\n",
    "        #     input_data = np.pad(input_data, ((0, 0), (0, 498 - input_data.shape[1])), mode='constant')\n",
    "\n",
    "        # Transpose the input tensor to match the expected order\n",
    "        input_data = np.transpose(input_data, (1, 0)) # still getting error: Error during inference: Cannot set tensor: Dimension mismatch. Got 498 but expected 1 for dimension 0 of input 0.\n",
    "\n",
    "        model.set_tensor(input_details[0]['index'], input_data)\n",
    "        model.invoke()\n",
    "\n",
    "        scores = model.get_tensor(output_details[0]['index'])\n",
    "        top_pred = np.argmax(scores, axis=1)[0]\n",
    "        top_pred_conf = np.max(scores, axis=1)[0]\n",
    "\n",
    "        label = labels[top_pred]\n",
    "        conf = round(top_pred_conf * 100, 2)\n",
    "\n",
    "        # Store individual predictions\n",
    "        segment_predictions.append((label, conf))\n",
    "\n",
    "    # Aggregate predictions (e.g., by averaging confidence scores)\n",
    "    aggregated_label, aggregated_conf = aggregate_predictions(segment_predictions)\n",
    "\n",
    "    return (aggregated_label, aggregated_conf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myNEWenv)",
   "language": "python",
   "name": "mynewenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
