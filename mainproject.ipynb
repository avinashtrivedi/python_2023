{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d2b66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12322162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkGenerator(word):\n",
    "    link='https://news.google.com/rss/search?q='\n",
    "    link+=word\n",
    "    return link\n",
    "#     print(link)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec5e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def xmlparse(link):\n",
    "    tree = ET.parse(link)\n",
    "# print(type(tree))\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    title=[]\n",
    "    link=[] \n",
    "    desc=[]\n",
    "    source=[]\n",
    "    date=[]\n",
    "    for child in root:\n",
    "        for i in range(8,len(child)):\n",
    "            for j in range(len(child[i])):\n",
    "                if child[i][j].tag=='title':\n",
    "                    title.append(child[i][j].text)\n",
    "                elif child[i][j].tag=='link':\n",
    "                    link.append(child[i][j].text)\n",
    "                elif child[i][j].tag=='description':\n",
    "                    desc.append(child[i][j].text)\n",
    "                elif child[i][j].tag=='source':\n",
    "                    source.append(child[i][j].text)\n",
    "                elif child[i][j].tag=='pubDate':\n",
    "                    date.append(child[i][j].text)\n",
    "    dict={'title':title,'link':link,'pubdate':date,'source':source}\n",
    "    df=pd.DataFrame(dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e2f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def businessToday(link):\n",
    "    response=requests.get(link)\n",
    "    author=''\n",
    "    soup=BeautifulSoup(response.text,'html.parser')   \n",
    "    content=soup.find('div',{'class':'content-area'})\n",
    "    try:\n",
    "        heading=content.find('div',{'class':'story-heading'}).text\n",
    "    except:\n",
    "        heading='No heading'\n",
    "    #     print(heading)\n",
    "    try:\n",
    "        subheading=content.find('div',{'class':'sab-head-tranlate-sec'}).text\n",
    "    except:\n",
    "        subheading='No subheading'\n",
    "        #     print(subheading)\n",
    "    try:\n",
    "        userdetail=content.find('div',{'class':'userdetail-share-main story-user-section'})\n",
    "        left=userdetail.find('div',{'class':'user-detial-left'})\n",
    "        branddetail=left.find('div',{'class':'brand-detial-main'})\n",
    "        date=branddetail.find('ul').text\n",
    "        date=date.replace('Updated ','')\n",
    "    except:\n",
    "        date='No date'\n",
    "        #     print(date)\n",
    "    try:\n",
    "        story=content.find('div',{'class':'stroy-870'})\n",
    "        main=story.find('div',{'class':'story-with-main-sec'})\n",
    "        storyFormat=main.find('div',{'class':'text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item'})\n",
    "        p=storyFormat.find_all('p')\n",
    "        news=[]\n",
    "        for i in p:\n",
    "            news.append(i.text)\n",
    "    except:\n",
    "        news='No data'\n",
    "            #     print(data)\n",
    "    dict={'Source':['Business Today'],'heading':[heading],'subheading':[subheading],'author':[author],'date':[date],'news':[news]}\n",
    "    df=pd.DataFrame(dict)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "871e4ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dynamic class\n",
    "def economicTimes(link):\n",
    "    author=''\n",
    "    response=requests.get(link)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    content=soup.find('div',{'class':'article_wrap'})\n",
    "    headline=content.find('div',{'class':'topPart clearfix tac fixedOnLoad'})\n",
    "    heading=headline.find('h1').text\n",
    "    subheading=''\n",
    "#     print(heading)\n",
    "    metadata=content.find('div',{'class':'bylineBox'})\n",
    "    contentwrapper=metadata.find('div',{'class':'dt contentwrapper'})\n",
    "    artbyline=contentwrapper.find('div',{'class':'dtc vam artByline'})\n",
    "    time=artbyline.find('time',{'class':'jsdtTime'}).text\n",
    "    time=time.replace('Last Updated: ','')\n",
    "#     print(time)\n",
    "#     author=artbyline.find('div',{'class':'auth eventDone'})\n",
    "#     a_nam=author.find('a').text\n",
    "#     print(a_name)\n",
    "    news=[]\n",
    "    newsdata=content.find('div',{'class':'edition clearfix'})\n",
    "    pagecontent=newsdata.find('div',{'class':'pageContent flt'})\n",
    "    article=pagecontent.find('article',{'class':'artData clr paywall'}).text\n",
    "#     p=article.find('p').text\n",
    "#     print(article)\n",
    "#     arttext=article.find('div',{'class':'artText medium'}).text\n",
    "#     br=arttext.find('em')\n",
    "#     for i in br:\n",
    "#         news.append(i.text)\n",
    "#     print(br)\n",
    "    dict={'Source':['Economic Times'],'heading':[heading],'subheading':[subheading],'author':[author],'date':[time],'news':[article]}\n",
    "    df=pd.DataFrame(dict)\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27629ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mint(link):\n",
    "    response=requests.get(link)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    content=soup.find('section',{'class':'mainSec'})\n",
    "    try:\n",
    "        head=content.find('div',{'class':'stickyCare'})\n",
    "        heading=head.find('h1',{'class':'headline'}).text\n",
    "    except:\n",
    "        heading='no heading'\n",
    "    data=[]\n",
    "    subheading=''\n",
    "#     print(heading)\n",
    "    try:\n",
    "        publish=head.find('span',{'class':'articleInfo pubtime'})\n",
    "        lastUpdate=publish.find_all('span')[1].text\n",
    "        lastUpdate=lastUpdate.replace('Updated: ','')\n",
    "    except:\n",
    "        lastUpdate='no date'\n",
    "        #     print(lastUpdate)\n",
    "    try:\n",
    "        author=head.find('span',{'class':'articleInfo author'})\n",
    "        name=author.find_all('a')\n",
    "        for i in name:\n",
    "            a_name=i.find('strong').text\n",
    "#             a_name=i.text\n",
    "    except:\n",
    "        a_name='No author'\n",
    "\n",
    "#     print(a_name)\n",
    "    try:\n",
    "        news=content.find('div',{'class':'contentSec'})\n",
    "        first=news.find('div',{'class':'FirstEle'})\n",
    "        data.append(first.text)\n",
    "    #     print(first.text)\n",
    "        second=news.find('div',{'class':'paywall'})\n",
    "        p=second.find_all('p');\n",
    "        for i in p:\n",
    "            data.append(i.text)\n",
    "    except:\n",
    "        data='No data'\n",
    "#         print(i.text)\n",
    "    dict={'Source':['Mint'],'heading':[heading],'subheading':[subheading],'author':[author],'date':[lastUpdate],'news':[data]}\n",
    "    df=pd.DataFrame(dict)\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18b81b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def businessStandard(link):\n",
    "    response=requests.get(link)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    content=soup.find('div',{'class':'story-detail'})\n",
    "    author=''\n",
    "    try:\n",
    "        heading=content.find('h1').text\n",
    "    except:\n",
    "        heading='no heading'\n",
    "#     print(heading.text)\n",
    "    try:\n",
    "        subheading=content.find('h2').text\n",
    "    except:\n",
    "        subheading='no sub'\n",
    "#     print(subheading.text)\n",
    "    try:\n",
    "        data=content.find('div',{'class':'storycontent'})\n",
    "        p=data.find_all('p')\n",
    "        if p==[]:\n",
    "            p=data.find_all('div')\n",
    "        news=[]\n",
    "        for i in p:\n",
    "            news.append(i.text)\n",
    "    except:\n",
    "        news='no news'\n",
    "            #     print(news)\n",
    "    try:\n",
    "        date=content.find('div',{'class':'story-first-time'})\n",
    "        p=date.find('p').text\n",
    "        p=p.replace('First Published: ','')\n",
    "    except:\n",
    "        p='no date'\n",
    "        #     print(p)\n",
    "    dict={'Source':['Business Standard'],'heading':[heading],'subheading':[subheading],'author':[author],'date':[p],'news':[news]}\n",
    "    df=pd.DataFrame(dict)\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50729f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moneyControl(link):\n",
    "    response=requests.get(link)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    content=soup.find('div',{'class':'page_left_wrapper'})\n",
    "    try:\n",
    "        heading=content.find('h1',{'class':'article_title artTitle'}).text\n",
    "    except:\n",
    "        heading=''\n",
    "        #     print(heading)\n",
    "    try:\n",
    "        subheading=content.find('h2',{'class':'article_desc'}).text\n",
    "    except:\n",
    "        subheading=''\n",
    "        #     print(subheading)\n",
    "    try:   \n",
    "        metadata=content.find('div',{'class':'clearfix'})\n",
    "        author=metadata.find('div',{'class':'article_author'}).text\n",
    "        author=author\n",
    "    except:\n",
    "        author=''\n",
    "        #     print(author.strip())\n",
    "    try:\n",
    "        dates=metadata.find('div',{'class':'article_schedule'}).text\n",
    "        dates=dates\n",
    "    except:\n",
    "        dates=''\n",
    "#     print(dates.strip())\n",
    "    try:\n",
    "        data=content.find('div',{'class':'content_wrapper arti-flow'})\n",
    "        p=data.find_all('p')\n",
    "        news=[]\n",
    "        for i in p:\n",
    "            news.append(i.text)\n",
    "    except:\n",
    "        news=''\n",
    "#     print(news)\n",
    "    dict={'Source':['Money Control'],'heading':[heading],'subheading':[subheading],'author':[author.strip()],'date':[dates.strip()],'news':[news]}\n",
    "    df=pd.DataFrame(dict)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb60f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toi(link):\n",
    "    response=requests.get(link)\n",
    "    author=''\n",
    "    subheading=''\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    content=soup.find('div',{'class':'okf2Z'})\n",
    "    try:\n",
    "#         print('hejjs')\n",
    "        heading=content.find('div',{'class':'pZFl7'}).text\n",
    "    except:\n",
    "        heading=''\n",
    "        #     print(heading.text)\n",
    "    try:\n",
    "        time=heading.find('div',{'class':'t8vf3 byline_action'})\n",
    "        date=time.find('span').text\n",
    "    except:\n",
    "        date=''\n",
    "#     print(date)\n",
    "    data=content.find('div',{'class':'JuyWl'})\n",
    "    data1=data.find('div',{'class':'vSlIC'})\n",
    "    data2=data1.find('div',{'class':'heightCalc'})\n",
    "    x=soup.find_all('div')\n",
    "    for i in x:\n",
    "        y=i.get('class')\n",
    "        if 'fewcent' in str(y):\n",
    "            classs=y\n",
    "    data3=data2.find('div',{'class':classs})\n",
    "    news=data3.find('div',{'class':'_s30J clearfix'}).text\n",
    "#     news=''\n",
    "        #     print(news)\n",
    "    dict={'Source':['TOI'],'heading':[heading],'subheading':[subheading],'author':[author],'date':[date],'news':[news]}\n",
    "    df=pd.DataFrame(dict)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8241bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = moneyControl(\"https://www.moneycontrol.com/news/business/fc-kohli-it-doyen-who-built-tcs-in-its-formative-years-no-more-6162061.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8da10000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ask those who knew him well and they would remember Faqir Chand Kohli, the first Chief Executive Officer (CEO) of Tata Consultancy Services (TCS), as the father of the Indian IT industry.',\n",
       " 'Kohli, who last spoke to Moneycontrol in October, passed away on November 26 of natural causes. He is survived by his wife and three children.',\n",
       " '\"Mr. Faqir Kohli formed and led TCS from its\\xa0founding days. He guided the company in its early years and defined the\\xa0vision for its growth,\" said Tata group patriarch and Chairman Emeritus Ratan N Tata.',\n",
       " '\"His early vision played an important role in creating the outstandingly successful global IT company that TCS has become today,\" Tata added.',\n",
       " 'Tata also said: \"Kohli\\'s\\xa0contribution in various technology-oriented areas was significant. and he will be remembered as one of the fathers of India’s successful IT industry.\"',\n",
       " 'He was gracious, unassuming, and always willing to help,\\xa0Tata noted.',\n",
       " 'Other senior Tata leaders echo those views.\\xa0“Kohli was a brilliant technocrat and a business leader with varied interests. He was passionate about the development of our nation and its youth,” said former CEO and Vice Chairman of TCS S Ramadorai, who took over after Kohli retired.',\n",
       " 'Kohli, who was 96 years old, ran TCS more like a promoter, which was to mean that it was his own company and that he never allowed resources to be wasted just because it could be put on the corporate balance sheet, said management consultant Hiru Bijlani, who was a long-time friend of the Kohlis.',\n",
       " '“He made very sure he ran a tight ship,” \\xa0Bijlani said, adding that Kohli had a\\xa0“tough-love” management style and pushed through more barriers for Indian IT than people are aware of.',\n",
       " 'That’s something that even Ramadorai recalls experiencing. “He always challenged me by presenting me with different situations and new opportunities in our early days. This was something I learned from him and imbibed as I grew to build my teams at TCS later,” Ramadorai said.',\n",
       " '“I will forever cherish the opportunity to have worked with a stalwart like him,” he added.',\n",
       " 'Kohli was roped in from the Tata Electric Companies, and was instrumental in the decision to bring IBM to India as part of Tata-IBM in 1991. His role in setting up TCS and running it later is well documented.',\n",
       " 'He became the director of the company in 1970 and was appointed as the first CEO of TCS later. He retired in 1999 at the age of 75 by which time the profits of TCS were as much as if not more than most of the other group companies, Bijlani said.',\n",
       " 'Kohli, who had a green thumb and spent time in his garden in Alibaugh, was also a frequent golfer. He shot to an 18-handicap and hit a long ball even at the age of 80, and applied the same approach to work. “His work continued well after he retired, with pursuits that included educating the less fortunate through word recognition programmes and by pushing for more recognition for engineering programmes and the industry in India,” Bijlani said.',\n",
       " 'In his free time, Kohli would continue to read up on the latest developments in technology and engineering and admitted in earlier interviews that most of it was “very technical”.',\n",
       " 'Both the career\\xa0highs that he cherished had to do with recognition from professional bodies. The Institute of Electrical and Electronics Engineers, or IEEE, which was a professional association for electronic engineering and electrical engineering with its corporate office in New York City, honoured Kohli with a fellowship, making him at the time the only non-American in the world to get it.',\n",
       " 'The other accomplishment he regarded highly was becoming a member and fellow of the South East Asia Computer Society and was the only non-Singaporean to get it.',\n",
       " 'Voltas\\'s former Managing Director Nawshir Khurody, who knew him in his early career, said: \"Whenever I reached him for help as a young TAS officer,\\xa0Kohli would set aside everything and reach out to help him. His passing has brought back memories of how few people like him are left in the Tata group. He was a humble genius and a very remarkable man.”',\n",
       " 'Khurody remembered how at the breakfast table in Pune at the Tata Management Training Centre, Kohli took the toast rack at breakfast,\\xa0handed it to him, and said \"here you need it more than me\".',\n",
       " 'Kohli \\xa0never cared what car he drove or what he wore or about the trappings of leadership and power. \"At the training centre, he would ask the most junior people the names of the trees and was never afraid to learn from them,\" Khurody recalled, adding that two things Kohli would tell everyone were: All software and computer work should be done in Indian languages and that India cannot become a super power until IT is extensively deployed across the country.',\n",
       " '\"We will always be reminded of the huge contribution Mr Kohli made to the Tata group. It is his vision, passion, discipline and commitment that set the culture in TCS. The grounded yet dynamic culture in TCS is a reflection of his strength of character, and I believe is what sets it apart from most of its competitors, said Cyrus Mistry, former Chairman of Tata group.',\n",
       " '\"His vision not only gave birth to TCS, but established the whole software industry in India, it is this tremendous contribution that earned him the coveted Padma Bhushan so richly deserved by him,\" he added.',\n",
       " 'A social tippler who would enjoy his single malt whiskey responsibly, Kohli was known to be direct and even ribbing friends on their dress-sense when they wore shirts that looked like table cloths.',\n",
       " 'At his home in the Air India Building at Nariman Point, guests were welcomed to warm hospitable entertainment with either jazz music or ghazals playing in the background.',\n",
       " 'Because TCS’ first office was opposite the Air India Building, where he lived, the joke was that he walked across the road and built the TCS building. Later he went there to work out of his office right until the end before the lockdown came into effect in the wake of the COVID-19 pandemic.',\n",
       " '“During my interactions with him, I had become a firm believer that most people rise to new challenges,” Ramadorai observed. “He was also my mentor, guide and a very close family friend, and his demise is a personal loss to our family.”',\n",
       " 'At his farewell, the Tata group organised a going away bash at the Taj Hotel in Colaba and had celebrated Indian flautist Hariprasad Chaurasia perform at the function which was attended by the top brass at the group.',\n",
       " '“The nation has lost a true visionary and legend today,” Ramadorai said.',\n",
       " 'Pavan Lall is a senior journalist based in Mumbai.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['news'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4416dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xmlSaver(link):\n",
    "    import requests\n",
    "\n",
    "#     URL = \"https://news.google.com/rss/search?q=NIFTY\"\n",
    "    URL=link\n",
    "\n",
    "    response = requests.get(URL)\n",
    "    from pathlib import Path\n",
    "    link=Path.home()\n",
    "    link=str(link)+'\\\\Downloads\\\\file.xml'\n",
    "    with open(link, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "508fdda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def scrappers(df,index):\n",
    "    source=df['source'][index]\n",
    "    if source=='Mint':\n",
    "        dataframe=mint(df['link'][index])\n",
    "        return dataframe\n",
    "    elif source=='Business Standard':\n",
    "        dataframe=businessStandard(df['link'][index])\n",
    "        return dataframe\n",
    "    elif source=='Economic Times':\n",
    "        dataframe=economicTimes(df['link'][index])\n",
    "        return dataframe\n",
    "    elif source=='Business Today':\n",
    "        dataframe=businessToday(df['link'][index])\n",
    "        return dataframe\n",
    "    elif source=='Times of India':\n",
    "        dataframe=toi(df['link'][index])\n",
    "    elif source=='Moneycontrol':\n",
    "        dataframe=moneyControl(df['link'][index])    \n",
    "#     else:\n",
    "#         print('working on it!!!')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "245febc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    word=input(\"Enter stock symbol to scrap\\n\")\n",
    "    link=linkGenerator(word)\n",
    "    file=xmlSaver(link)\n",
    "#     print(file)\n",
    "#     df=xmlparse('C:\\\\Users\\\\PadamShree\\\\Desktop\\\\project 6th sem\\\\file.xml')\n",
    "    from pathlib import Path\n",
    "    link=Path.home()\n",
    "    link=str(link)+'\\\\Downloads\\\\file.xml'\n",
    "    df=xmlparse(link)\n",
    "#     df=link\n",
    "    counts=df['source'].value_counts()\n",
    "\n",
    "\n",
    "    temp_dict={}\n",
    "    df_all=pd.DataFrame(temp_dict)\n",
    "    for i in range(0,100):\n",
    "        if df['source'][i]=='Economic Times' :\n",
    "            continue\n",
    "#         df_all.append(scrappers(df,i))\n",
    "#     return df_all\n",
    "        \n",
    "        dict=scrappers(df,i)\n",
    "#         print(dict)\n",
    "        df_all=pd.concat([dict,df_all])\n",
    "    return df_all\n",
    "#     scrappers(df,0)\n",
    "#     scrappers(df,1)\n",
    "#     scrappers(df,2)\n",
    "#     scrappers(df,3)\n",
    "#     df=scrappers(df,4)\n",
    "#     print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce16dd83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter stock symbol to scrap\n",
      "tcs\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    df = main()\n",
    "#     df = df.transpose()\n",
    "    df.to_csv('main.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "dea1c5b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec776f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
