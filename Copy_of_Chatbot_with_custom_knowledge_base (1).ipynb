{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwaLK4kD1Uar"
   },
   "source": [
    "#Introduction\n",
    "\n",
    "This notebook has all the code you need to create your own chatbot with custom knowledge base using GPT-3. \n",
    "\n",
    "Follow the instructions for each steps and then run the code sample. In order to run the code, you need to press \"play\" button near each code sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rD4Qzglp3J-h"
   },
   "source": [
    "#Download the data for your custom knowledge base\n",
    "For the demonstration purposes we are going to use ----- as our knowledge base. You can download them to your local folder from the github repository by running the code below.\n",
    "Alternatively, you can put your own custom data into the local folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "aUE9bDt4xp3Z",
    "outputId": "a23c15c7-bf55-4bb5-8e5d-185300c6177e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is Warba bank</td>\n",
       "      <td>Warba Bank was established on February 17, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Who is the Chairman of Warba Bank?</td>\n",
       "      <td>Mr. Hamad M. AlSayer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Who is the Vice Chairman of Warba Bank?</td>\n",
       "      <td>Mr. Bader K. AlShalfan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Who is the CEO of Warba Bank?</td>\n",
       "      <td>Mr. Shaheen H. Al-Ghanem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Who is the Deputy Chief Executive Officer Supp...</td>\n",
       "      <td>Mr. Anwar Bader Al Ghaith</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                          Questions  \\\n",
       "0   1                                 What is Warba bank   \n",
       "1   2                 Who is the Chairman of Warba Bank?   \n",
       "2   3            Who is the Vice Chairman of Warba Bank?   \n",
       "3   4                      Who is the CEO of Warba Bank?   \n",
       "4   5  Who is the Deputy Chief Executive Officer Supp...   \n",
       "\n",
       "                                             Answers  \n",
       "0  Warba Bank was established on February 17, 201...  \n",
       "1                              Mr. Hamad M. AlSayer   \n",
       "2                             Mr. Bader K. AlShalfan  \n",
       "3                          Mr. Shaheen H. Al-Ghanem   \n",
       "4                         Mr. Anwar Bader Al Ghaith   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('D:\\OneDrive - NITT\\Custom_Download\\Shegardi_dataset.xlsx',sheet_name = 'Sheet1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XiUyHP4T2g5F"
   },
   "source": [
    "# Install the dependicies\n",
    "Run the code below to install the depencies we need for our functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6LL4rxT6_W7h",
    "outputId": "0f6cfbac-6593-4b69-afff-af150b00bb94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.4.28.tar.gz (138 kB)\n",
      "     ---------------------------------------- 0.0/138.6 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/138.6 kB ? eta -:--:--\n",
      "     -------- ---------------------------- 30.7/138.6 kB 330.3 kB/s eta 0:00:01\n",
      "     -------- ---------------------------- 30.7/138.6 kB 330.3 kB/s eta 0:00:01\n",
      "     -------- ---------------------------- 30.7/138.6 kB 330.3 kB/s eta 0:00:01\n",
      "     ---------- -------------------------- 41.0/138.6 kB 140.9 kB/s eta 0:00:01\n",
      "     ---------------- -------------------- 61.4/138.6 kB 204.8 kB/s eta 0:00:01\n",
      "     ------------------------ ------------ 92.2/138.6 kB 276.8 kB/s eta 0:00:01\n",
      "     ------------------------ ------------ 92.2/138.6 kB 276.8 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 112.6/138.6 kB 252.2 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 112.6/138.6 kB 252.2 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 112.6/138.6 kB 252.2 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 112.6/138.6 kB 252.2 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 112.6/138.6 kB 252.2 kB/s eta 0:00:01\n",
      "     ------------------------------------ 138.6/138.6 kB 200.6 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting dataclasses_json\n",
      "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.0.113-py3-none-any.whl (396 kB)\n",
      "     ---------------------------------------- 0.0/396.0 kB ? eta -:--:--\n",
      "     - ----------------------------------- 20.5/396.0 kB 320.0 kB/s eta 0:00:02\n",
      "     --- --------------------------------- 41.0/396.0 kB 653.6 kB/s eta 0:00:01\n",
      "     ----- ------------------------------- 61.4/396.0 kB 656.4 kB/s eta 0:00:01\n",
      "     ----- ------------------------------- 61.4/396.0 kB 656.4 kB/s eta 0:00:01\n",
      "     ----- ------------------------------- 61.4/396.0 kB 656.4 kB/s eta 0:00:01\n",
      "     ----- ------------------------------- 61.4/396.0 kB 656.4 kB/s eta 0:00:01\n",
      "     ----- ------------------------------- 61.4/396.0 kB 656.4 kB/s eta 0:00:01\n",
      "     ----------------- ------------------ 194.6/396.0 kB 535.8 kB/s eta 0:00:01\n",
      "     ----------------- ------------------ 194.6/396.0 kB 535.8 kB/s eta 0:00:01\n",
      "     ------------------ ----------------- 204.8/396.0 kB 461.0 kB/s eta 0:00:01\n",
      "     ------------------ ----------------- 204.8/396.0 kB 461.0 kB/s eta 0:00:01\n",
      "     ------------------ ----------------- 204.8/396.0 kB 461.0 kB/s eta 0:00:01\n",
      "     ------------------ ----------------- 204.8/396.0 kB 461.0 kB/s eta 0:00:01\n",
      "     ------------------ ----------------- 204.8/396.0 kB 461.0 kB/s eta 0:00:01\n",
      "     ----------------------- ------------ 256.0/396.0 kB 383.4 kB/s eta 0:00:01\n",
      "     ----------------------- ------------ 256.0/396.0 kB 383.4 kB/s eta 0:00:01\n",
      "     ----------------------- ------------ 256.0/396.0 kB 383.4 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 317.4/396.0 kB 392.8 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 337.9/396.0 kB 395.7 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 368.6/396.0 kB 388.7 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 368.6/396.0 kB 388.7 kB/s eta 0:00:01\n",
      "     ------------------------------------ 396.0/396.0 kB 379.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from llama-index) (1.23.5)\n",
      "Collecting tenacity<9.0.0,>=8.2.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting openai>=0.26.4\n",
      "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
      "     ---------------------------------------- 0.0/70.1 kB ? eta -:--:--\n",
      "     ----- ---------------------------------- 10.2/70.1 kB ? eta -:--:--\n",
      "     ----- ---------------------------------- 10.2/70.1 kB ? eta -:--:--\n",
      "     ---------------------- --------------- 41.0/70.1 kB 326.8 kB/s eta 0:00:01\n",
      "     ---------------------- --------------- 41.0/70.1 kB 326.8 kB/s eta 0:00:01\n",
      "     ---------------------- --------------- 41.0/70.1 kB 326.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 70.1/70.1 kB 294.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from llama-index) (1.5.3)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.3.1-cp39-cp39-win_amd64.whl (581 kB)\n",
      "     ---------------------------------------- 0.0/581.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/581.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/581.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/581.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/581.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/581.4 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 61.4/581.4 kB ? eta -:--:--\n",
      "     ---- ---------------------------------- 71.7/581.4 kB 2.0 MB/s eta 0:00:01\n",
      "     ----- ------------------------------- 92.2/581.4 kB 871.5 kB/s eta 0:00:01\n",
      "     ----- ------------------------------- 92.2/581.4 kB 871.5 kB/s eta 0:00:01\n",
      "     ------ ----------------------------- 112.6/581.4 kB 504.4 kB/s eta 0:00:01\n",
      "     ------ ----------------------------- 112.6/581.4 kB 504.4 kB/s eta 0:00:01\n",
      "     ------- ---------------------------- 122.9/581.4 kB 400.9 kB/s eta 0:00:02\n",
      "     ------- ---------------------------- 122.9/581.4 kB 400.9 kB/s eta 0:00:02\n",
      "     -------- --------------------------- 143.4/581.4 kB 355.0 kB/s eta 0:00:02\n",
      "     -------- --------------------------- 143.4/581.4 kB 355.0 kB/s eta 0:00:02\n",
      "     -------- --------------------------- 143.4/581.4 kB 355.0 kB/s eta 0:00:02\n",
      "     -------- --------------------------- 143.4/581.4 kB 355.0 kB/s eta 0:00:02\n",
      "     -------- --------------------------- 143.4/581.4 kB 355.0 kB/s eta 0:00:02\n",
      "     ------------ ----------------------- 194.6/581.4 kB 294.9 kB/s eta 0:00:02\n",
      "     ------------ ----------------------- 204.8/581.4 kB 289.5 kB/s eta 0:00:02\n",
      "     ------------ ----------------------- 204.8/581.4 kB 289.5 kB/s eta 0:00:02\n",
      "     ------------ ----------------------- 204.8/581.4 kB 289.5 kB/s eta 0:00:02\n",
      "     ------------- ---------------------- 225.3/581.4 kB 269.8 kB/s eta 0:00:02\n",
      "     -------------- --------------------- 235.5/581.4 kB 257.5 kB/s eta 0:00:02\n",
      "     -------------- --------------------- 235.5/581.4 kB 257.5 kB/s eta 0:00:02\n",
      "     --------------- -------------------- 256.0/581.4 kB 253.6 kB/s eta 0:00:02\n",
      "     --------------- -------------------- 256.0/581.4 kB 253.6 kB/s eta 0:00:02\n",
      "     --------------- -------------------- 256.0/581.4 kB 253.6 kB/s eta 0:00:02\n",
      "     ----------------- ------------------ 276.5/581.4 kB 243.4 kB/s eta 0:00:02\n",
      "     ----------------- ------------------ 276.5/581.4 kB 243.4 kB/s eta 0:00:02\n",
      "     ----------------- ------------------ 286.7/581.4 kB 232.9 kB/s eta 0:00:02\n",
      "     ----------------- ------------------ 286.7/581.4 kB 232.9 kB/s eta 0:00:02\n",
      "     ------------------- ---------------- 307.2/581.4 kB 231.8 kB/s eta 0:00:02\n",
      "     ------------------- ---------------- 307.2/581.4 kB 231.8 kB/s eta 0:00:02\n",
      "     ------------------- ---------------- 317.4/581.4 kB 223.4 kB/s eta 0:00:02\n",
      "     ------------------- ---------------- 317.4/581.4 kB 223.4 kB/s eta 0:00:02\n",
      "     -------------------- --------------- 337.9/581.4 kB 220.8 kB/s eta 0:00:02\n",
      "     -------------------- --------------- 337.9/581.4 kB 220.8 kB/s eta 0:00:02\n",
      "     ---------------------- ------------- 358.4/581.4 kB 222.9 kB/s eta 0:00:02\n",
      "     ---------------------- ------------- 358.4/581.4 kB 222.9 kB/s eta 0:00:02\n",
      "     ---------------------- ------------- 368.6/581.4 kB 216.4 kB/s eta 0:00:01\n",
      "     ------------------------ ----------- 389.1/581.4 kB 218.5 kB/s eta 0:00:01\n",
      "     ------------------------ ----------- 399.4/581.4 kB 218.5 kB/s eta 0:00:01\n",
      "     ------------------------ ----------- 399.4/581.4 kB 218.5 kB/s eta 0:00:01\n",
      "     ------------------------ ----------- 399.4/581.4 kB 218.5 kB/s eta 0:00:01\n",
      "     ------------------------- ---------- 409.6/581.4 kB 211.3 kB/s eta 0:00:01\n",
      "     -------------------------- --------- 430.1/581.4 kB 215.0 kB/s eta 0:00:01\n",
      "     -------------------------- --------- 430.1/581.4 kB 215.0 kB/s eta 0:00:01\n",
      "     --------------------------- -------- 450.6/581.4 kB 215.1 kB/s eta 0:00:01\n",
      "     --------------------------- -------- 450.6/581.4 kB 215.1 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 460.8/581.4 kB 210.5 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 460.8/581.4 kB 210.5 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 481.3/581.4 kB 210.8 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 481.3/581.4 kB 210.8 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 491.5/581.4 kB 208.2 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 491.5/581.4 kB 208.2 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 512.0/581.4 kB 208.5 kB/s eta 0:00:01\n",
      "     -------------------------------- --- 532.5/581.4 kB 210.2 kB/s eta 0:00:01\n",
      "     -------------------------------- --- 532.5/581.4 kB 210.2 kB/s eta 0:00:01\n",
      "     -------------------------------- --- 532.5/581.4 kB 210.2 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 542.7/581.4 kB 206.5 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 563.2/581.4 kB 206.9 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 563.2/581.4 kB 206.9 kB/s eta 0:00:01\n",
      "     -----------------------------------  573.4/581.4 kB 204.8 kB/s eta 0:00:01\n",
      "     ------------------------------------ 581.4/581.4 kB 206.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from openai>=0.26.4->llama-index) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from openai>=0.26.4->llama-index) (2.28.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from openai>=0.26.4->llama-index) (3.7.4.post0)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 0.0/49.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/49.1 kB ? eta -:--:--\n",
      "     -------- ------------------------------- 10.2/49.1 kB ? eta -:--:--\n",
      "     -------- ------------------------------- 10.2/49.1 kB ? eta -:--:--\n",
      "     ----------------------- -------------- 30.7/49.1 kB 262.6 kB/s eta 0:00:01\n",
      "     ----------------------- -------------- 30.7/49.1 kB 262.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 49.1/49.1 kB 191.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from langchain->llama-index) (1.4.46)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-win_amd64.whl (323 kB)\n",
      "     ---------------------------------------- 0.0/323.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/323.6 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/323.6 kB ? eta -:--:--\n",
      "     --- --------------------------------- 30.7/323.6 kB 262.6 kB/s eta 0:00:02\n",
      "     --- --------------------------------- 30.7/323.6 kB 262.6 kB/s eta 0:00:02\n",
      "     --- --------------------------------- 30.7/323.6 kB 262.6 kB/s eta 0:00:02\n",
      "     ---- -------------------------------- 41.0/323.6 kB 163.4 kB/s eta 0:00:02\n",
      "     ---- -------------------------------- 41.0/323.6 kB 163.4 kB/s eta 0:00:02\n",
      "     ---- -------------------------------- 41.0/323.6 kB 163.4 kB/s eta 0:00:02\n",
      "     ---- -------------------------------- 41.0/323.6 kB 163.4 kB/s eta 0:00:02\n",
      "     ---- -------------------------------- 41.0/323.6 kB 163.4 kB/s eta 0:00:02\n",
      "     ---------- -------------------------- 92.2/323.6 kB 180.8 kB/s eta 0:00:02\n",
      "     ---------- -------------------------- 92.2/323.6 kB 180.8 kB/s eta 0:00:02\n",
      "     ---------- -------------------------- 92.2/323.6 kB 180.8 kB/s eta 0:00:02\n",
      "     ------------ ----------------------- 112.6/323.6 kB 177.2 kB/s eta 0:00:02\n",
      "     ------------ ----------------------- 112.6/323.6 kB 177.2 kB/s eta 0:00:02\n",
      "     ------------ ----------------------- 112.6/323.6 kB 177.2 kB/s eta 0:00:02\n",
      "     ------------- ---------------------- 122.9/323.6 kB 160.2 kB/s eta 0:00:02\n",
      "     ------------- ---------------------- 122.9/323.6 kB 160.2 kB/s eta 0:00:02\n",
      "     --------------- -------------------- 143.4/323.6 kB 160.8 kB/s eta 0:00:02\n",
      "     --------------- -------------------- 143.4/323.6 kB 160.8 kB/s eta 0:00:02\n",
      "     ----------------- ------------------ 153.6/323.6 kB 152.8 kB/s eta 0:00:02\n",
      "     ----------------- ------------------ 153.6/323.6 kB 152.8 kB/s eta 0:00:02\n",
      "     ----------------- ------------------ 153.6/323.6 kB 152.8 kB/s eta 0:00:02\n",
      "     ------------------- ---------------- 174.1/323.6 kB 156.5 kB/s eta 0:00:01\n",
      "     ------------------- ---------------- 174.1/323.6 kB 156.5 kB/s eta 0:00:01\n",
      "     --------------------- -------------- 194.6/323.6 kB 161.5 kB/s eta 0:00:01\n",
      "     --------------------- -------------- 194.6/323.6 kB 161.5 kB/s eta 0:00:01\n",
      "     ---------------------- ------------- 204.8/323.6 kB 155.6 kB/s eta 0:00:01\n",
      "     ---------------------- ------------- 204.8/323.6 kB 155.6 kB/s eta 0:00:01\n",
      "     ------------------------- ---------- 225.3/323.6 kB 161.9 kB/s eta 0:00:01\n",
      "     ------------------------- ---------- 225.3/323.6 kB 161.9 kB/s eta 0:00:01\n",
      "     -------------------------- --------- 235.5/323.6 kB 155.0 kB/s eta 0:00:01\n",
      "     -------------------------- --------- 235.5/323.6 kB 155.0 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 256.0/323.6 kB 160.5 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 256.0/323.6 kB 160.5 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 256.0/323.6 kB 160.5 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 256.0/323.6 kB 160.5 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 256.0/323.6 kB 160.5 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 256.0/323.6 kB 160.5 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 256.0/323.6 kB 160.5 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 307.2/323.6 kB 158.4 kB/s eta 0:00:01\n",
      "     -----------------------------------  317.4/323.6 kB 158.5 kB/s eta 0:00:01\n",
      "     ------------------------------------ 323.6/323.6 kB 160.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from langchain->llama-index) (1.8.2)\n",
      "Collecting PyYAML<7,>=6\n",
      "  Using cached PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from pandas->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from pandas->llama-index) (2022.7.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tiktoken->llama-index) (2022.10.31)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (1.8.2)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-win_amd64.whl (34 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (22.2.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses_json->llama-index) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from pydantic<2,>=1->langchain->llama-index) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests>=2.20->openai>=0.26.4->llama-index) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests>=2.20->openai>=0.26.4->llama-index) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests>=2.20->openai>=0.26.4->llama-index) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from SQLAlchemy<2,>=1->langchain->llama-index) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses_json->llama-index) (0.4.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tqdm->openai>=0.26.4->llama-index) (0.4.6)\n",
      "Building wheels for collected packages: llama-index\n",
      "  Building wheel for llama-index (setup.py): started\n",
      "  Building wheel for llama-index (setup.py): finished with status 'done'\n",
      "  Created wheel for llama-index: filename=llama_index-0.4.28-py3-none-any.whl size=204750 sha256=e8dc7b9bb7d36e624200938df80a01523d1497c54be07730f831f2d3d1b95b49\n",
      "  Stored in directory: c:\\users\\avitr\\appdata\\local\\pip\\cache\\wheels\\d1\\86\\c1\\57e42e658690c7d65de12f542829dc03026c003b1685293106\n",
      "Successfully built llama-index\n",
      "Installing collected packages: typing-inspect, tenacity, PyYAML, marshmallow, frozenlist, async-timeout, tiktoken, marshmallow-enum, aiosignal, dataclasses_json, aiohttp, openai, langchain, llama-index\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.1.0\n",
      "    Uninstalling tenacity-8.1.0:\n",
      "      Successfully uninstalled tenacity-8.1.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\avitr\\\\anaconda3\\\\Lib\\\\site-packages\\\\~-ml\\\\_yaml.cp39-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.0.113-py3-none-any.whl (396 kB)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from langchain) (1.4.46)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Using cached aiohttp-3.8.4-cp39-cp39-win_amd64.whl (323 kB)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
      "  Using cached dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: PyYAML<7,>=6 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from langchain) (1.8.2)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp39-cp39-win_amd64.whl (34 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.1.1)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Using cached marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Using cached marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from SQLAlchemy<2,>=1->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n",
      "Installing collected packages: marshmallow, frozenlist, async-timeout, marshmallow-enum, aiosignal, dataclasses-json, aiohttp, langchain\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 3.0.1\n",
      "    Uninstalling async-timeout-3.0.1:\n",
      "      Successfully uninstalled async-timeout-3.0.1\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.7.4.post0\n",
      "    Uninstalling aiohttp-3.7.4.post0:\n",
      "      Successfully uninstalled aiohttp-3.7.4.post0\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.7 frozenlist-1.3.3 langchain-0.0.113 marshmallow-3.19.0 marshmallow-enum-1.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "discord-py 1.7.3 requires aiohttp<3.8.0,>=3.6.0, but you have aiohttp 3.8.4 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZ_oD0w_N478",
    "outputId": "4f3350c9-97b3-4e7e-e2eb-1cca7f6602fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'git' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/irina1nik/context_data.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9z7XuGGycuk",
    "outputId": "2c4b9aee-750d-4457-e439-c1de986518b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to output_dataset.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "data_path = r\"D:\\OneDrive - NITT\\Custom_Download\\Shegardi_dataset.xlsx\"\n",
    "data = pd.read_excel(data_path)\n",
    "\n",
    "# Process the data (in this example, combining the 'Questions' and 'Answers' columns)\n",
    "def preprocess_data(data):\n",
    "    text = \"\"\n",
    "    for index, row in data.iterrows():\n",
    "        text += f\"Question: {row['Questions']}\\nAnswer: {row['Answers']}\\n\"\n",
    "    return text\n",
    "\n",
    "text_data = preprocess_data(data)\n",
    "\n",
    "# Save the processed data as a text file\n",
    "output_file = \"output_dataset.txt\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(text_data)\n",
    "\n",
    "print(f\"Data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbuYetOy25eM"
   },
   "source": [
    "# Define the functions\n",
    "The following code defines the functions we need to construct the index and query it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "UelAqQgk_yIt"
   },
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n",
    "from langchain import OpenAI\n",
    "import sys\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def construct_index(directory_path):\n",
    "    # set maximum input size\n",
    "    max_input_size = 4096\n",
    "    # set number of output tokens\n",
    "    num_outputs = 2000\n",
    "    # set maximum chunk overlap\n",
    "    max_chunk_overlap = 20\n",
    "    # set chunk size limit\n",
    "    chunk_size_limit = 600 \n",
    "\n",
    "    # define LLM\n",
    "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.5, model_name=\"text-davinci-003\", max_tokens=num_outputs))\n",
    "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
    " \n",
    "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
    "    \n",
    "    index = GPTSimpleVectorIndex(\n",
    "        documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper\n",
    "    )\n",
    "\n",
    "    index.save_to_disk('index.json')\n",
    "\n",
    "    return index\n",
    "\n",
    "def ask_ai():\n",
    "    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n",
    "    while True: \n",
    "        query = input(\"What do you want to ask? \")\n",
    "        response = index.query(query, response_mode=\"compact\")\n",
    "        display(Markdown(f\"Response: <b>{response.response}</b>\"))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vz1jp33jGumu"
   },
   "source": [
    "# Set OpenAI API Key\n",
    "You need an OPENAI API key to be able to run this code.\n",
    "\n",
    "If you don't have one yet, get it by [signing up](https://platform.openai.com/overview). Then click your account icon on the top right of the screen and select \"View API Keys\". Create an API key.\n",
    "\n",
    "Then run the code below and paste your API key into the text input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RoJHE4fsAT3w",
    "outputId": "a1fb0c40-2822-4664-a84a-16f1c55954dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paste your OpenAI key here and hit enter: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\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = input(\"Paste your OpenAI key here and hit enter:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVrddlAL4I_v"
   },
   "source": [
    "#Construct an index\n",
    "Now we are ready to construct the index. This will take every file in the folder 'data', split it into chunks, and embed it with OpenAI's embeddings API.\n",
    "\n",
    "**Notice:** running this code will cost you credits on your OpenAPI account ($0.02 for every 1,000 tokens). If you've just set up your account, the free credits that you have should be more than enough for this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDdXwLoEn5Td",
    "outputId": "001d3c0f-487c-48e6-8d15-fe73ea8e7836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_data  output_dataset.txt  Shegardi_dataset.xlsx\n",
      "index.json    sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kCYTE2EqBB7O",
    "outputId": "d260e20a-16e1-4048-a1f0-89b6923d6a98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "2023-03-15 19:13:25.344 > [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 4337 tokens\n",
      "2023-03-15 19:13:25.347 > [build_index_from_documents] Total embedding token usage: 4337 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.indices.vector_store.vector_indices.GPTSimpleVectorIndex at 0x7ff06bd58df0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct_index(\"context_data/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipJ_gYxN5cWh"
   },
   "source": [
    "#Ask questions\n",
    "It's time to have fun and test our AI. Run the function that queries GPT and type your question into the input. \n",
    "\n",
    "If you've used the provided example data for your custom knowledge base, here are a few questions that you can ask:\n",
    "1. Why people cook at home? Make classification\n",
    "2. Make classification about what frustrates people about cooking?\n",
    "3. Brainstorm marketing campaign ideas for an air fryer that would appeal people that cook at home\n",
    "4. Which kitchen appliences people use most often?\n",
    "5. What people like about cooking at home?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "id": "s_uwsPGEIGsb",
    "outputId": "23df3f2e-b103-4c40-f17d-36a2a32b0f1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to ask? who are you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 591 tokens\n",
      "2023-03-15 19:06:53.420 > [query] Total LLM token usage: 591 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 3 tokens\n",
      "2023-03-15 19:06:53.427 > [query] Total embedding token usage: 3 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Response: <b>\n",
       "I am Shegardi, and I am an employee of Warba Bank, located in Kuwait.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to ask? who is the ceo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 585 tokens\n",
      "2023-03-15 19:07:13.796 > [query] Total LLM token usage: 585 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 5 tokens\n",
      "2023-03-15 19:07:13.803 > [query] Total embedding token usage: 5 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Response: <b>\n",
       "Answer: Mr. Shaheen H. Al-Ghanem</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to ask? mention credit cards typs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 619 tokens\n",
      "2023-03-15 19:07:58.646 > [query] Total LLM token usage: 619 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 6 tokens\n",
      "2023-03-15 19:07:58.649 > [query] Total embedding token usage: 6 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Response: <b>Answer: Elite Dual Chip Mastercard, World Elite Mastercard, World Mastercard, Platinum Mastercard, VISA Signature, VISA Platinum, VISA Prepaid.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-73fd53e5fb33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mask_ai\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-515a4ff9c382>\u001b[0m in \u001b[0;36mask_ai\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPTSimpleVectorIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What do you want to ask? \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"compact\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Response: <b>{response.response}</b>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "ask_ai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zfp5k7DUTlN7",
    "outputId": "71f71755-cb73-4653-a211-47271e035fdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.20.0-py2.py3-none-any.whl (9.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (4.5.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (8.4.0)\n",
      "Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.8/dist-packages (from streamlit) (23.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (7.1.2)\n",
      "Requirement already satisfied: pandas<2,>=0.25 in /usr/local/lib/python3.8/dist-packages (from streamlit) (1.3.5)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-13.3.2-py3-none-any.whl (238 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.7/238.7 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (5.3.0)\n",
      "Collecting gitpython!=3.1.19\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.8/dist-packages (from streamlit) (1.5.1)\n",
      "Collecting validators>=0.2\n",
      "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting blinker>=1.0.0\n",
      "  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests>=2.4 in /usr/local/lib/python3.8/dist-packages (from streamlit) (2.25.1)\n",
      "Collecting pympler>=0.9\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 KB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: altair<5,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit) (4.2.2)\n",
      "Collecting watchdog\n",
      "  Downloading watchdog-2.3.1-py3-none-manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from streamlit) (1.22.4)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.8/dist-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from streamlit) (6.2)\n",
      "Collecting semver\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.8/dist-packages (from streamlit) (3.19.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from altair<5,>=3.2.0->streamlit) (2.11.3)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair<5,>=3.2.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair<5,>=3.2.0->streamlit) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair<5,>=3.2.0->streamlit) (4.3.3)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=1.4->streamlit) (3.14.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2,>=0.25->streamlit) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil->streamlit) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit) (2022.12.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.4->streamlit) (1.24.3)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown-it-py<3.0.0,>=2.2.0\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from validators>=0.2->streamlit) (4.4.2)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->altair<5,>=3.2.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit) (22.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit) (0.19.3)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit) (5.12.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: validators\n",
      "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19581 sha256=17091d150ebca64e15bafc35e19fb6704148d467844a46fc0ed9bb4e4ed44558\n",
      "  Stored in directory: /root/.cache/pip/wheels/19/09/72/3eb74d236bb48bd0f3c6c3c83e4e0c5bbfcbcad7c6c3539db8\n",
      "Successfully built validators\n",
      "Installing collected packages: watchdog, validators, smmap, semver, pympler, pygments, mdurl, blinker, pydeck, markdown-it-py, gitdb, rich, gitpython, streamlit\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.6.1\n",
      "    Uninstalling Pygments-2.6.1:\n",
      "      Successfully uninstalled Pygments-2.6.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed blinker-1.5 gitdb-4.0.10 gitpython-3.1.31 markdown-it-py-2.2.0 mdurl-0.1.2 pydeck-0.8.0 pygments-2.14.0 pympler-1.0.1 rich-13.3.2 semver-2.13.0 smmap-5.0.0 streamlit-1.20.0 validators-0.20.0 watchdog-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5LtJQb6TlLi"
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from llama_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n",
    "from langchain import OpenAI\n",
    "import sys\n",
    "import os\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQeDg7ciTlE6",
    "outputId": "5c507d3a-0af3-4cb9-d852-b07e9148f457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paste your OpenAI key here and hit enter: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\n",
      "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
      "\n",
      "Error: Invalid value: File does not exist: streamlit_app.py\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from llama_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n",
    "from langchain import OpenAI\n",
    "import sys\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "def construct_index(directory_path):\n",
    "        # set maximum input size\n",
    "    max_input_size = 4096\n",
    "    # set number of output tokens\n",
    "    num_outputs = 2000\n",
    "    # set maximum chunk overlap\n",
    "    max_chunk_overlap = 20\n",
    "    # set chunk size limit\n",
    "    chunk_size_limit = 600 \n",
    "\n",
    "    # define LLM\n",
    "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.5, model_name=\"text-davinci-003\", max_tokens=num_outputs))\n",
    "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
    " \n",
    "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
    "    \n",
    "    index = GPTSimpleVectorIndex(\n",
    "        documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper\n",
    "    )\n",
    "\n",
    "    index.save_to_disk('index.json')\n",
    "\n",
    "    return index\n",
    "\n",
    "def ask_ai():\n",
    "    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n",
    "    while True: \n",
    "        query = input(\"What do you want to ask? \")\n",
    "        response = index.query(query, response_mode=\"compact\")\n",
    "        display(Markdown(f\"Response: <b>{response.response}</b>\"))\n",
    "  \n",
    "os.environ[\"OPENAI_API_KEY\"] = input(\"Paste your OpenAI key here and hit enter:\")\n",
    "st.title(\"AI Question-Answering App\")\n",
    "\n",
    "query = st.text_input(\"What do you want to ask?\")\n",
    "if query:\n",
    "    response = ask_ai(query)\n",
    "    st.write(f\"Response: {response.response}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fluUWoH9pzu6",
    "outputId": "0913686c-631e-48b7-de78-491c5f916f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting gradio\n",
      "  Downloading gradio-3.21.0-py3-none-any.whl (15.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting websockets>=10.0\n",
      "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.21.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-multipart\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from gradio) (2023.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from gradio) (1.22.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from gradio) (1.3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from gradio) (2.11.3)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from gradio) (1.10.5)\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.94.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from gradio) (3.8.4)\n",
      "Collecting httpx\n",
      "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from gradio) (8.4.0)\n",
      "Collecting mdit-py-plugins<=0.3.3\n",
      "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from gradio) (6.0)\n",
      "Collecting aiofiles\n",
      "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.8/dist-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from gradio) (4.5.0)\n",
      "Collecting orjson\n",
      "  Downloading orjson-3.8.7-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.7/140.7 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from gradio) (2.25.1)\n",
      "Requirement already satisfied: markupsafe in /usr/local/lib/python3.8/dist-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from gradio) (3.5.3)\n",
      "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from gradio) (4.2.2)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.13.0->gradio) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.13.0->gradio) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.13.0->gradio) (23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.8/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Collecting linkify-it-py<3,>=1\n",
      "  Downloading linkify_it_py-2.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (3.0.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.8.2)\n",
      "Collecting starlette<0.27.0,>=0.26.1\n",
      "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpcore<0.17.0,>=0.15.0\n",
      "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx->gradio) (2022.12.7)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting rfc3986[idna2008]<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (2.10)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn->gradio) (7.1.2)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting anyio<5.0,>=3.0\n",
      "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (5.12.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->gradio) (1.15.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair>=4.2.0->gradio) (3.14.0)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4711 sha256=f58dbdd7cbddc08903c6bb8b84ab4c0f62b4776d1e5f6a3693a2ee8eb34bf537\n",
      "  Stored in directory: /root/.cache/pip/wheels/ff/5b/59/913b443e7369dc04b61f607a746b6f7d83fb65e2e19fcc958d\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: rfc3986, pydub, ffmpy, websockets, uc-micro-py, sniffio, python-multipart, orjson, h11, aiofiles, uvicorn, mdit-py-plugins, linkify-it-py, anyio, starlette, httpcore, httpx, fastapi, gradio\n",
      "Successfully installed aiofiles-23.1.0 anyio-3.6.2 fastapi-0.94.1 ffmpy-0.3.0 gradio-3.21.0 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 linkify-it-py-2.0.0 mdit-py-plugins-0.3.3 orjson-3.8.7 pydub-0.25.1 python-multipart-0.0.6 rfc3986-1.5.0 sniffio-1.3.0 starlette-0.26.1 uc-micro-py-1.0.1 uvicorn-0.21.0 websockets-10.4\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "AbCYHwiWpzsm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llama_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n",
    "from langchain import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "iW1OTV1Fpzp8"
   },
   "outputs": [],
   "source": [
    "def ask_ai(query):\n",
    "    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n",
    "    response = index.query(query, response_mode=\"compact\")\n",
    "    return response.response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "v4UOhXvqpznl"
   },
   "outputs": [],
   "source": [
    "iface = gr.Interface(fn=ask_ai, inputs=\"text\", outputs=\"text\", title=\"The following is a conversation with a human called Shegardi. Shegardi is helpful, precise, truthful, and very friendly.  Also, Shegardi is an employee of Warba Bank, located in Kuwait. Shegardi will only use the information provided to him. \", \n",
    "                     description=\"Enter a question and get an answer from Shegardi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "l3Ra3NMpTlAU",
    "outputId": "592a8cd8-4dd8-41f0-c0d3-6e698e8ef0a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://50abe92bf005485500.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://50abe92bf005485500.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "ub97marSr5tt"
   },
   "outputs": [],
   "source": [
    "def ask_ai(query):\n",
    "    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n",
    "    response = index.query(query, response_mode=\"compact\")\n",
    "    return response.response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "bBu11bjKr5rf"
   },
   "outputs": [],
   "source": [
    "def app():\n",
    "    st.title(\"AI Question Answering\")\n",
    "    query = st.text_input(\"Enter a question:\")\n",
    "    if query:\n",
    "        response = ask_ai(query)\n",
    "        st.markdown(f\"**Response:** {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "vd6g48ugr5o0"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5rG_HJNr5md"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCbAvZJ5r5jy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W5DCm56RTk9m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YEf0HQ6mTk7X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
