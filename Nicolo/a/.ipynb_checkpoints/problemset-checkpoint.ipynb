{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkzxtYlnSjuE"
   },
   "source": [
    "# Homework 1: Probability Review and Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCbU4DF0SpWZ"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riVk6z40SqCg"
   },
   "source": [
    "To run and solve this assignment, you must have access to a working Jupyter Notebook installation. We recommend Google Colab. If you are already familiar with Jupyter and have your own installation, you may use it; however, you will have to tweak Colab-specific commands we've entered here (for example, file uploads).\n",
    "\n",
    "To use Google Colab:\n",
    "\n",
    "1. Download this `ipynb` file.\n",
    "2. Navigate to https://colab.research.google.com/ and select `Upload` in the pop-up window.\n",
    "3. Upload this file. It will then open in Colab.\n",
    "4. Now, upload the dataset associated with this assignment to the Colab runtime. On the left side of the screen, click on \"Files\" (denoted by a **folder icon**) and then click on \"Upload to session storage\" (denoted by a **file icon with an up arrow**). Select the dataset (`BostonHousing.csv`).\n",
    "\n",
    "The below statements assume that you have already followed these instructions. If you need help with Python syntax, NumPy, or Matplotlib, you might find Week 1 discussion material useful.\n",
    "\n",
    "To run code in a cell or to render Markdown+LaTeX press Ctrl+Enter or \"`Run`\" button above. To edit any code or text cell, double-click on its content. Put your solution into boxes marked with **`[double click here to add a solution]`** and press Ctrl+Enter to render text. You can add cells via `+` sign at the top left corner.\n",
    "\n",
    "**Submission instructions**: please upload your completed solution file as well as a scan of any handwritten answers to Gradescope by the due date (see Schedule)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keOx0ipxStbz"
   },
   "source": [
    "## Probability Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiQGllyKSv7E"
   },
   "source": [
    "### 1. Conditional Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vku-U0Drx-On"
   },
   "source": [
    "Let's assume that COVID PCR test false positive rate is 0.02 (test positive\n",
    "but is actually negative), false negative rate is 0.3 (test negative but is actually positive).\n",
    "Assume that 30% of the population are actually having COVID. If one were to take a test and\n",
    "receive a negative result, what is the likelihood that the person still has COVID? (Show your steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhy93i3xZz3w"
   },
   "source": [
    "**Answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSDKs1yglQ3_"
   },
   "source": [
    "### 2. Expectation and Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_vLgSp5_F6_"
   },
   "source": [
    "Let $X_1,X_2,X_3,X_4 \\sim N(\\mu,\\sigma^2)$ sampled IID from known distributions. Define:\n",
    "\n",
    "$$U = X_1 X_2 - 2X_3 X_4$$\n",
    "$$V = X_2 X_3 + 2X_1 X_4$$\n",
    "\n",
    "Answer the following questions in terms of $\\mu$ and $\\sigma$ :\n",
    "\n",
    "**a.** Find $E[U]$ and $E[V]$.\n",
    "\n",
    "**b.** What are $Var[U]$ and $Var[V]$?\n",
    "\n",
    "**c.** What is $Cov[U,V]$?\n",
    "\n",
    "**d.** What is covariance and what is correlation? Explain in your own words.\n",
    "\n",
    "**e.** Show that the covariance of 2 independent random variables is zero but a zero covariance does not directly imply 2 random variables are independent? (hint: to show something is not true, you can try to come up with a counter-example)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROlqMnXqF-2Q"
   },
   "source": [
    "**Answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkIuQwJEUfAE"
   },
   "source": [
    "### 3. Closed-Form Maximum Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qS42_KZMWDjX"
   },
   "source": [
    "Assume that we are given $n$ iid samples $(x_1, x_2, ..., x_n)$ from each $P(x \\ | \\ \\theta)$ given below. Compute the maximum likelihood estimates (MLEs) for the parameter $\\theta$ of the given distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIvOZxwXawsZ"
   },
   "source": [
    "**a.** $P(x\\ | \\ \\theta) = \\theta^3 x^2 e^{-\\theta x}$ for $x \\geq 0$\n",
    "\n",
    "**b.** $P(x\\ | \\ \\theta_1, \\theta_2) = \\frac{1}{\\theta_1\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\frac{(x-\\theta_2)^2}{\\theta_1^2}}$\n",
    "\n",
    "**c.**  $P(x \\ | \\ \\theta) = \\frac{1}{1-\\theta^3}$ for $ \\theta \\leq x \\leq 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-Y3kNyjcwEp"
   },
   "source": [
    "**Answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0fib1Qsg5Up"
   },
   "source": [
    "## ML Basics with Python\n",
    "The following section will walk you through performing basic ML operations with Python, including loading, splitting, and observing a dataset using `pandas`, `sklearn`, and `matplotlib`, as well as running linear regression over features of a dataset using `sklearn`'s built-in methods. Add you solution to the skeleton code whenever you see `###Add code here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zh0AL1R4z0FJ"
   },
   "source": [
    "### 4. Basics of `numpy`: solving a linear system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYz0AA6Rz0FJ"
   },
   "source": [
    "#### 4.a. Using np.linalg.solve()\n",
    "\n",
    "Let $A = \\begin{bmatrix} 1 & 6 \\\\ 7  & 4 \\end{bmatrix}$ and $b = \\begin{bmatrix} -1 \\\\ 12 \\end{bmatrix}$\n",
    "\n",
    "Find $x = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}$ where $Ax=b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4D1AYxpaz0FK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "### ADD CODE HERE:\n",
    "### Create numpy arrays for A and b\n",
    "\n",
    "#Solve for x using np.linalg.solve().\n",
    "\n",
    "print(A,b,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaVK4_7K97r-"
   },
   "source": [
    "Now, let\n",
    "\n",
    "$$A = \\begin{bmatrix} 1 & 5 & 2 \\\\ 3 & 1 & 4 \\\\ -1 & 9 & 0 \\end{bmatrix}, b = \\begin{bmatrix} -2 \\\\ 7 \\\\ -11 \\end{bmatrix}.$$\n",
    "\n",
    "Try using np.linalg.solve() to find $x = [x_1, x_2, x_3]^T$. If you are unable to solve using np.linalg.solve() try using np.linalg.lstsq(). Does any other solution of this equation exist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjr7NULedl2y"
   },
   "source": [
    "**Answer here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPC3KX6X96wg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "### ADD CODE here\n",
    "\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPfSPPbez0FM"
   },
   "source": [
    "#### 4.b. Using matrix multiplication\n",
    "\n",
    "Solve for $x$ and print out its value: $ x = \\begin{bmatrix} 2 & 2 & 2 \\end{bmatrix} \\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 3 \\\\ 3 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37w1QpbSz0FM"
   },
   "outputs": [],
   "source": [
    "### ADD CODE HERE:\n",
    "\n",
    "\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNQVqbSqz0FN"
   },
   "source": [
    "### 5. Data Visualization with `pandas` and `matplotlib`\n",
    "\n",
    "In the following set of problems, we'll look at how we can use linear regression to predict the price of a house in Boston based on its various features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "251XoOEty4hA"
   },
   "source": [
    "Each record in the database describes a Boston suburb or town. The data was drawn from the Boston Standard Metropolitan Statistical Area (SMSA) in 1970. The attributes are deﬁned as follows:\n",
    "\n",
    "**1.CRIM**: per capita crime rate by town\n",
    "\n",
    "**2.ZN**: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "\n",
    "**3.INDUS**: proportion of non-retail business acres per town\n",
    "\n",
    "**4.CHAS**: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "\n",
    "**5.NOX**: nitric oxides concentration (parts per 10 million)\n",
    "\n",
    "**6.RM**: average number of rooms per dwelling\n",
    "\n",
    "**7.AGE**: proportion of owner-occupied units built prior to 1940\n",
    "\n",
    "**8.DIS**: weighted distances to ﬁve Boston employment centers\n",
    "\n",
    "**9.RAD**: index of accessibility to radial highways\n",
    "\n",
    "**10.TAX**: full-value property-tax rate per $10,000\n",
    "\n",
    "**11.PTRATIO**: pupil-teacher ratio by town 12. B: 1000(Bk−0.63)2 where Bk is the proportion of blacks by town 13. LSTAT: % lower status of the population\n",
    "\n",
    "**12. MEDV**: Median value of owner-occupied homes in $1000s\n",
    "\n",
    "We can see that the input attributes have a mixture of units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiT3LG8ly4hB"
   },
   "source": [
    "#### Load the dataset and look at the features\n",
    "First, we'll use `pandas` to load the dataset and use the `head()` function to get a glimpse of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVsUG9fJ0kNt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "housing_data = pd.read_csv(\"BostonHousing.csv\")\n",
    "housing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOk_kj84y4hC"
   },
   "source": [
    "We can also use `describe()` function to see the distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7g0by7GU0mcU"
   },
   "outputs": [],
   "source": [
    "housing_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9qASD_ny4hD"
   },
   "source": [
    "#### 5.a. Visualize the features\n",
    "We're going to model Boston housing price using a linear regression model. To do that, we'd like to visualize the data and choose features that are well-suited for a linear model. Use `matplotlib` to plot each feature in the `housing` list below against the target, `medv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JjpyqHei0hLp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "housing_features = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio']\n",
    "target = housing_data['medv']\n",
    "\n",
    "# Create a figure to hold our plots\n",
    "plt.figure(figsize=(28, 7))\n",
    "for i, feature in enumerate(housing_features):\n",
    "    # Create subplots for each feature within this figure\n",
    "    plt.subplot(1, len(housing_features) , i+1)\n",
    "    ### ADD CODE HERE:\n",
    "    ### Set `x` (The feature we want to plot)\n",
    "    ### and `y` (The value that we want to estimate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###\n",
    "    plt.scatter(x, y, marker='o')\n",
    "    plt.title(feature)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('medv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPemYgApy4hD"
   },
   "source": [
    "#### 5.b. Select the best feature for a linear regression model\n",
    "Which feature looks like it would work well for fitting a linear regression model? Pick just one, and assign it to the variable called `price_features`. *There might be more than one correct answer, feel free to experiment with all the features.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0oVcFNqy4hD"
   },
   "outputs": [],
   "source": [
    "### ADD CODE HERE:\n",
    "### Set `price_features` (A feature to use to fit our linear regression model)\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "price_labels = housing_data['medv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oFUI4Wiy4hE"
   },
   "source": [
    "***Briefly explain your rationale for choosing this feature in the cell below. Also, pick one of the features that you didn't choose and explain why that feature is not good for our purpose.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoLw9B-ny4hE"
   },
   "source": [
    "**Answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sF3TZxqty4hE"
   },
   "source": [
    "### 6. Train-Test Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvHCkVP-y4hE"
   },
   "source": [
    "Train-test splitting is a fundamental practice in machine learning. When fitting a model, we'd to divide our data into separate training and testing sets in order to fairly evaluate how our model performs. In this section, we will learn two ways to split our datasets: using `numpy` and `sklearn`. First, let us convert our panda dataframes to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lzq9QPNzy4hE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Convert our pandas dataframes (price_features and price_labels) to numpy arrays using np.asarray()\n",
    "price_features = np.asarray(price_features).reshape(-1,1)\n",
    "price_labels = np.asarray(price_labels).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGxShJiuy4hE"
   },
   "source": [
    "#### 6.1. Spliting data using `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KlH7WP2y4hF"
   },
   "source": [
    "First, let us shuffle our data (feel free to comment out the shuffling to see if there's anything change). This is a very common practice in ML to make the data \"random\" and improve the\n",
    "generalization of the model at the end. To do this, we first need to stack our data to keep the indices correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJkg6IGZpSDN"
   },
   "outputs": [],
   "source": [
    "#combine the features and the labels to a data matrix. The feature is the first row, the label is the second row\n",
    "data_matrix = np.stack([price_labels, price_features], axis = 0)\n",
    "# shuffle our data\n",
    "np.random.shuffle(data_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDlqxdrLy4hF"
   },
   "source": [
    "Now that we have a \"random\" data matrix, let us split the matrix into train set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHmOHbAVy4hF"
   },
   "outputs": [],
   "source": [
    "### Add code here\n",
    "### Split the data_matrix into x_train_np, x_test_np, y_train_np, y_test_np where (x_train_np, y_train_np) is the training set  and (x_test_np, y_test_np) is the test set\n",
    "### (the training set is typically 80% the length of the whole dataset).\n",
    "### Print out the shape of x_train_np and x_test_np.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySxQs6mby4hG"
   },
   "source": [
    "#### 6.2. Splitting data using `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHUIV5Ffy4hG"
   },
   "source": [
    "Now we know how to split the train/test set manually using `numpy`, let us look at how we can split the data using `train_test_split`, which is a more common way to split the dataset. *Refer to, the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to better understand how this method is used.* Observe the sizes of the resulting datasets, and which samples were placed where."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n91fj3QW1O6i"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert our pandas dataframes to numpy arrays\n",
    "price_features = np.asarray(price_features).reshape(-1,1)\n",
    "price_labels = np.asarray(price_labels).reshape(-1,1)\n",
    "\n",
    "### ADD CODE HERE:\n",
    "### Use train_test_split to split the price_features and price_lables into training and testing sets.\n",
    "### Print out the resulting data splits and their sizes.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1mRYroMy4hG"
   },
   "source": [
    "### 7. Linear Regression\n",
    "Now, we'll fit a linear regression model to our data using `sklearn`'s built-in linear regression method. We will also test the model with our test data, and see how it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrFwo6dDy4hH"
   },
   "source": [
    "#### 7.a. Fit the linear regression model with our data\n",
    "Use `sklearn`'s built-in linear regression method to fit a model using the training data you got as a result of problem 6. *Refer to the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) to better understand how this method is used.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0Y7Z6I4y4hH"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "### ADD CODE HERE:\n",
    "### Use the LinearRegression() method to fit a model using the training data. You can use either the training data that you\n",
    "### split using sklearn or numpy. If you implemented everything correctly, they should yield the same result.\n",
    "\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPMbeXJWy4hH"
   },
   "source": [
    "#### 7.b. Plot the data against the model\n",
    "Use `matplotlib` to visualize the fit of the model alongside the housing feature data. You will need to extract the parameters of the model, the coefficient $w$ and the intercept $b$, to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJX3RSOF1omz"
   },
   "outputs": [],
   "source": [
    "### ADD CODE HERE:\n",
    "### Extract the coefficient of the model, w\n",
    "### Extract the intercept of the model, b\n",
    "\n",
    "###\n",
    "\n",
    "# Create plot figure\n",
    "plt.figure(figsize=(20, 5))\n",
    "### ADD CODE HERE:\n",
    "### Use plt.plot() to plot the model curve\n",
    "### Use plt.scatter() to plot the original feature data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "plt.title(\"OLS fit\")\n",
    "plt.xlabel(\"Your feature\") # change 'your feature' to the feature that you choose to plot\n",
    "plt.ylabel(\"medv\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOEdBtmRy4hH"
   },
   "source": [
    "#### 7.c. Plot the true targets against our estimated values\n",
    "Let's see how well our model performs! Plot the model's estimates of the price targets on our test data from problem 5 alongside the real values. Include the model fit as well for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtBo-nmsy4hI"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "### ADD CODE HERE:\n",
    "### Use plt.plot() to plot the model curve\n",
    "### Use plt.scatter() to plot the test data and corresponding values estimated by our model\n",
    "### Use plt.scatter() to plot the test data and corresponding target values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "plt.title(\"OLS fit\")\n",
    "plt.xlabel(\"Your feature\") # change 'your feature' to the feature that you choose to plot\n",
    "plt.ylabel(\"Medv\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
