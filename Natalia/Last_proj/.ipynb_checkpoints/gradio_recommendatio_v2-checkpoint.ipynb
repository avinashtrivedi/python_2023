{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "767a297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import (\n",
    "    AutoModel, AutoConfig, \n",
    "    AutoTokenizer, logging\n",
    ")\n",
    "logging.set_verbosity_error()\n",
    "logging.set_verbosity_warning()\n",
    "\n",
    "# train_text = data['AAPL']['2014-01-01'] #train['excerpt'][:16].tolist()\n",
    "max_seq_length = 512\n",
    "chkpoint1 = 'bert-base-uncased'\n",
    "def get_embedding_bert(tweet_text):\n",
    "    \n",
    "#     task='sentiment'\n",
    "    _pretrained_model = chkpoint1\n",
    "\n",
    "    config = AutoConfig.from_pretrained(_pretrained_model)\n",
    "    config.update({'output_hidden_states':True}) \n",
    "    # config.update({'max_position_embeddings':256})\n",
    "    model_bertweet = AutoModelForSequenceClassification.from_pretrained(_pretrained_model, config=config)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(_pretrained_model,use_fast=False)\n",
    "    \n",
    "    features = tokenizer.batch_encode_plus(\n",
    "        [tweet_text],\n",
    "        add_special_tokens=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_seq_length,\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "        return_attention_mask=True\n",
    "    )\n",
    "    outputs = model_bertweet(features['input_ids'], features['attention_mask'])\n",
    "    all_hidden_states = torch.stack(outputs['hidden_states']) #  torch.stack(outputs[2]) \n",
    "    \n",
    "    return all_hidden_states[-1][:, 0].cpu().detach().numpy()[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "291ec75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS = [\"MLP\", \"RF\", \"Adaboost\",\"XgBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5850feaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77b4612e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7872\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x28acd62bc70>, 'http://127.0.0.1:7872/', None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def translate(text):\n",
    "    \"\"\"\n",
    "    Translate the text from source lang to target lang\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('Embedding_chkpoint_1.csv')\n",
    "    df['Embedding_chkpoint_1'] = df['Embedding_chkpoint_1'].apply(lambda x: eval(x))\n",
    "    \n",
    "    temp = df.copy()\n",
    "    y = get_embedding_bert(text)\n",
    "    x_embed = np.array([i for i in temp['Embedding_chkpoint_1']])\n",
    "    cs = cosine_similarity(x_embed,np.array(y).reshape(1,-1))\n",
    "    temp['similarity'] = cs\n",
    "    temp = temp.sort_values('similarity',ascending=False)\n",
    "    temp = temp[['original_title','similarity','genres','popularity']].head(10)\n",
    "    return temp\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=translate,\n",
    "    inputs=[\n",
    "#         gr.components.Dropdown(label=\"Model\", choices=MODELS),\n",
    "        gr.components.Textbox(label=\"Text\")\n",
    "        \n",
    "#         gr.components.Dropdown(label=\"Target Language\", choices=LANGS),\n",
    "    ],\n",
    "    outputs= gr.Dataframe(), #[\"text\"],\n",
    "#     examples=[[\"Building a translation demo with Gradio is so easy!\", \"eng_Latn\", \"spa_Latn\"]],\n",
    "    cache_examples=False,\n",
    "    title=\"Recommendation Demo\",\n",
    "#     description=\"This demo is a simplified version of the original [NLLB-Translator](https://huggingface.co/spaces/Narrativaai/NLLB-Translator) space\"\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b28686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3632149b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
